{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Langchain basics \n",
    "## ENV setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -Uq langchain==0.2.7 langchain-aws langgraph==0.1.5 httpx  shortuuid pymysql pandas pygraphviz matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Langchain with bedrock invoke api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "llm = ChatBedrock( model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                  # streaming=True,\n",
    "                # callbacks=[StreamingStdOutCallbackHandler()],\n",
    "                model_kwargs=dict(temperature=0.1),\n",
    "                 credentials_profile_name=\"default\")\n",
    "\n",
    "llm_fast = ChatBedrock( model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "                  streaming=True,\n",
    "                callbacks=[StreamingStdOutCallbackHandler()],\n",
    "                model_kwargs=dict(temperature=0.5),\n",
    "                 credentials_profile_name=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Non-stream llm to create a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='亚马逊Bedrock的知识库是一项全面托管的服务,可帮助您从摄取到检索和提示增强实现整个检索增强生成(RAG)工作流程,而无需构建与数据源的自定义集成并管理数据流,从而推动了您在RAG工作流程中所能做到的边界。', additional_kwargs={'usage': {'prompt_tokens': 89, 'completion_tokens': 107, 'total_tokens': 196}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 89, 'completion_tokens': 107, 'total_tokens': 196}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-3a20f621-2a74-4f8b-b1da-bbeeea4e7786-0', usage_metadata={'input_tokens': 89, 'output_tokens': 107, 'total_tokens': 196})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "resp = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Chinese\",\n",
    "        \"input\": \"Knowledge Bases for Amazon Bedrock is a fully managed service that helps you implement the entire Retrieval Augmented Generation (RAG) workflow from ingestion to retrieval and prompt augmentation without having to build custom integrations to data sources and manage data flows, pushing the boundaries for what you can do in your RAG workflows..\",\n",
    "    }\n",
    ")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use stream llm to create a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "亚马逊 Bedrock 的知识库是一种完全托管的服务,它可以帮助您实现整个检索增强生成(RAG)工作流程,从摄取到检索和提示增强,无需构建与数据源的自定义集成和管理数据流,从而推动了您在 RAG 工作流程中可以实现的边界。"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm_fast\n",
    "_ = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Chinese\",\n",
    "        \"input\": \"Knowledge Bases for Amazon Bedrock is a fully managed service that helps you implement the entire Retrieval Augmented Generation (RAG) workflow from ingestion to retrieval and prompt augmentation without having to build custom integrations to data sources and manage data flows, pushing the boundaries for what you can do in your RAG workflows..\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
